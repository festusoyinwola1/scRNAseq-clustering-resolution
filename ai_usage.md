# AI Usage Documentation

This project utilized AI tools (ChatGPT and Google Gemini) for assistance with explanations, troubleshooting, and code refinement. All computational analyses, including data loading, preprocessing, clustering, visualization, and metrics, were conducted manually by the author in Google Colab, and all results were independently verified.

# How AI Was Used
- Clarifying the purpose and function of Scanpy commands and parameters  
- Helping debug error messages during clustering and UMAP generation
- Suggesting improvements to code structure and readability  
- Explaining how to structure the GitHub repository for reproducibility  
- Assisting in writing and formatting the draft project proposal and draft report  
- Providing guidance on best practices for documentation (README, ai_usage.md, repo structure)
- AI helped rephrase wording in some sections of the report, which I reviewed to ensure clarity, accuracy, and alignment with my own understanding of the analysis.
- Assisting in formatting Markdown, README sections, and organizing the overall project.

# What AI Did NOT Do
- AI did not generate or modify any dataset  
- AI did not execute any analysis code (all code was run manually in Google Colab / Jupyter environments)  
- AI did not create figures, UMAPs, or clustering outputs
- All figures, metrics, CSV files, and results were generated by my own execution of code in Colab  
- AI did not make decisions about parameter selection or scientific interpretation

All computations, clustering analyses, and figure generation are performed manually in Python using Scanpy.  
Prompts, responses, and verification notes will be included in the final project submission for transparency.

# Verification of AI Output
Every code block was:
- Independently executed by me in Colab.
- The results (CSVs and PNGs) were downloaded directly from the Colab environment.
- Uploaded to GitHub to ensure full reproducibility.
  
Whenever AI provided code explanations or debugging suggestions, all changes were independently validated by:
- Running the code directly in the Jupyter notebook  
- Checking outputs for correctness  
- Reviewing parameter effects on clustering  
- Ensuring reproducibility through Git and GitHub history

